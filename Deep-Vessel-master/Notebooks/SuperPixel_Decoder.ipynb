{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from skimage import io, color, measure\n",
    "from skimage.util import img_as_float, img_as_ubyte\n",
    "from skimage.segmentation import slic, mark_boundaries\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import time\n",
    "from six.moves import xrange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_img = pd.read_pickle('../Data/mean_img_no_class_bias.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATCH_DIM = 31\n",
    "BATCH_SIZE = 100 # Must be a perfect square\n",
    "NUM_CLASSES = 2\n",
    "SP_COMPACTNESS = 1\n",
    "SP_SIGMA = 1\n",
    "NUM_SP=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_path(directory):\n",
    "    imgs = glob.glob(directory + '/images/*.tif')\n",
    "    imgs.sort()\n",
    "    #a = [x.split('/')[-1].split('.')[0] for x in train]\n",
    "    \n",
    "    mask = glob.glob(directory + '/mask/*.gif')\n",
    "    mask.sort()\n",
    "    #b = [x.split('/')[-1].split('.')[0] for x in mask]\n",
    "    \n",
    "    gt = glob.glob(directory + '/1st_manual/*.gif')\n",
    "    gt.sort()\n",
    "    #c = [x.split('/')[-1].split('.')[0] for x in gt]\n",
    "    \n",
    "    return map(os.path.abspath, imgs), map(os.path.abspath, mask), map(os.path.abspath, gt)\n",
    "\n",
    "train, mask_train, gt_train =  get_path('../Data/DRIVE/training')\n",
    "test, mask_test, mask_gt = get_path('../Data/DRIVE/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images, keep_prob, fc_hidden_units1=512):\n",
    "    \"\"\" Builds the model as far as is required for running the network\n",
    "    forward to make predictions.\n",
    "\n",
    "    Args:\n",
    "        images: Images placeholder, from inputs().\n",
    "        keep_prob: Probability used for Droupout in the final Affine Layer\n",
    "        fc_hidden_units1: Number of hidden neurons in final Affine layer\n",
    "    Returns:\n",
    "        softmax_linear: Output tensor with the computed logits.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('h_conv1') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[4, 4, 3, 64], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        biases = tf.get_variable('biases', shape=[64], initializer=tf.constant_initializer(0.05))\n",
    "        \n",
    "        # Flattening the 3D image into a 1D array\n",
    "        x_image = tf.reshape(images, [-1,PATCH_DIM,PATCH_DIM,3])\n",
    "        z = tf.nn.conv2d(x_image, weights, strides=[1, 1, 1, 1], padding='VALID')\n",
    "        h_conv1 = tf.nn.relu(z+biases, name=scope.name)\n",
    "    with tf.variable_scope('h_conv2') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[4, 4, 64, 64], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        biases = tf.get_variable('biases', shape=[64], initializer=tf.constant_initializer(0.05))\n",
    "        z = tf.nn.conv2d(h_conv1, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        h_conv2 = tf.nn.relu(z+biases, name=scope.name)\n",
    "    \n",
    "    h_pool1 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME', name='h_pool1')\n",
    "    \n",
    "    with tf.variable_scope('h_conv3') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[4, 4, 64, 64], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        biases = tf.get_variable('biases', shape=[64], initializer=tf.constant_initializer(0.05))\n",
    "        z = tf.nn.conv2d(h_pool1, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        h_conv3 = tf.nn.relu(z+biases, name=scope.name)\n",
    "        \n",
    "    h_pool2 = tf.nn.max_pool(h_conv3, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME', name='h_pool2')\n",
    "    \n",
    "    with tf.variable_scope('h_fc1') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[7**2*64, fc_hidden_units1], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable('biases', shape=[fc_hidden_units1], initializer=tf.constant_initializer(0.05))\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        \n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, weights) + biases, name = 'h_fc1')\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "        \n",
    "        \n",
    "    with tf.variable_scope('h_fc2') as scope:\n",
    "        weights = tf.get_variable('weights', shape=[fc_hidden_units1, NUM_CLASSES], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable('biases', shape=[NUM_CLASSES])\n",
    "        \n",
    "        logits = (tf.matmul(h_fc1_drop, weights) + biases)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def placeholder_inputs(batch_size):\n",
    "    \"\"\"Generate placeholder variables to represent the input tensors.\n",
    "    Args:\n",
    "        batch_size: The batch size will be baked into both placeholders.\n",
    "    Returns:\n",
    "        images_placeholder: Images placeholder.\n",
    "    \"\"\"\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(batch_size, PATCH_DIM**2*3))\n",
    "    return images_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nbd(image, point):\n",
    "    i = point[0]\n",
    "    j = point[1]\n",
    "    h = int(PATCH_DIM/2)\n",
    "    return image[i-h:i+h+1,j-h:j+h+1].reshape(-1)\n",
    "def segment_region(segmented, row_col, segments_slic, region_id, prediction):\n",
    "    a = row_col[segments_slic==region_id]\n",
    "    segmented[a[:,0],a[:,1]] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = io.imread(train[0])\n",
    "mask = img_as_float(io.imread(mask_train[0]))\n",
    "gt = img_as_float(io.imread(gt_train[0]))\n",
    "mean_np_img = np.asarray(mean_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segments_slic = slic(image, n_segments=NUM_SP, compactness=SP_COMPACTNESS, \n",
    "                     sigma= SP_SIGMA, convert2lab = True)\n",
    "segments_slic = segments_slic + 1  # So that no labelled region is 0 and ignored by regionprops\n",
    "regions = measure.regionprops(segments_slic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sp_image = mark_boundaries(image, segments_slic,[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 / 329960\n",
      "Time taken - > 1.850338\n",
      "96 / 329960\n",
      "Time taken - > 0.000120\n",
      "100030 / 329960\n",
      "Time taken - > 21.055947\n",
      "100062 / 329960\n",
      "Time taken - > 0.000255\n",
      "100095 / 329960\n",
      "Time taken - > 0.000124\n",
      "200049 / 329960\n",
      "Time taken - > 30.053467\n",
      "200065 / 329960\n",
      "Time taken - > 0.011845\n",
      "200083 / 329960\n",
      "Time taken - > 0.000156\n",
      "300011 / 329960\n",
      "Time taken - > 23.617220\n",
      "300041 / 329960\n",
      "Time taken - > 0.000225\n",
      "300058 / 329960\n",
      "Time taken - > 0.000198\n",
      "300098 / 329960\n",
      "Time taken - > 0.000205\n"
     ]
    }
   ],
   "source": [
    "segmented = np.zeros(image.shape[:2])\n",
    "# We will use arrays to index the image and mask later\n",
    "cols, rows = np.meshgrid(np.arange(image.shape[1]), np.arange(image.shape[0]))\n",
    "row_col = np.stack([rows,cols], axis = 2)\n",
    "region_no = 1\n",
    "feed = np.zeros((BATCH_SIZE, PATCH_DIM**2*3))\n",
    "feed_count = 0\n",
    "pixel_count = 0\n",
    "predictions = np.zeros(BATCH_SIZE)\n",
    "region_count = np.zeros(BATCH_SIZE)\n",
    "h = PATCH_DIM/2\n",
    "\n",
    "begin = time.time()\n",
    "start_time = time.time()\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    # Generate placeholders for the images and labels.\n",
    "    images_placeholder = placeholder_inputs(BATCH_SIZE)\n",
    "\n",
    "    # Build a Graph that computes predictions from the inference model.\n",
    "    logits = inference(images_placeholder, 1.0, 512)\n",
    "    sm = softmax(logits)\n",
    "\n",
    "    # Create a saver for writing training checkpoints.\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # Create a session for running Ops on the Graph.\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, '../Data/model.ckpt')\n",
    "        for r in regions:\n",
    "            c = r.coords[0]\n",
    "            \n",
    "            pixel_count += len(r.coords)\n",
    "            if np.mod(pixel_count, 100000) < BATCH_SIZE:\n",
    "                print \"%d / %d\"%(pixel_count, image.shape[0]*image.shape[1])\n",
    "                current_time = time.time()\n",
    "                print \"Time taken - > %f\" % (current_time - start_time)\n",
    "                start_time = current_time\n",
    "            \n",
    "            skip = (c[0]>h+1)&(c[0]<image.shape[0]-h-1)&(c[1]>h+1)&(c[1]<image.shape[1]-h-1)\n",
    "            if (int(mask[c[0], c[1]]) == 0) or (not skip):   # Reject if a pixel of the mask is black\n",
    "                region_no += 1\n",
    "                \n",
    "            else:\n",
    "                # It is important to chose a point carefully\n",
    "                # If the compactness is too less, this point maybe connected\n",
    "                # to points far away\n",
    "                if feed_count < BATCH_SIZE-1:\n",
    "                    feed_count += 1\n",
    "                    feed[feed_count] = nbd(image,c)\n",
    "                    region_count[feed_count] = region_no\n",
    "                else:\n",
    "                    feed = feed - mean_np_img\n",
    "\n",
    "                    # Get predictions and draw accordingly on black image    \n",
    "                    predictions = sess.run([sm],\n",
    "                                   feed_dict={images_placeholder: feed})\n",
    "                    predictions = np.asarray(predictions).reshape(BATCH_SIZE, NUM_CLASSES)\n",
    "\n",
    "                    predictions = predictions[:,1]\n",
    "                    map(lambda x:segment_region(segmented, row_col, segments_slic,\n",
    "                                                region_count[x], predictions[x]),\n",
    "                                                np.arange(feed_count))\n",
    "                    # Reset everything after passing feed to feedforward\n",
    "                    feed = np.zeros((BATCH_SIZE, PATCH_DIM**2*3))\n",
    "                    predictions = np.zeros(BATCH_SIZE)\n",
    "                    region_count = np.zeros(BATCH_SIZE)\n",
    "                    feed_count = 0\n",
    "                    \n",
    "                \n",
    "                region_no += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time = 141.789766 secs\n"
     ]
    }
   ],
   "source": [
    "print \"Total time = %f secs\" % ((time.time()-begin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segmented = np.multiply(segmented,mask)\n",
    "io.imsave(\"../Data/sp_segmented.png\", segmented)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
